{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f762d6fcdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 55\n"
     ]
    }
   ],
   "source": [
    " tokens = set(''.join(names))### YOUR CODE HERE: all unique characters go here, padding included!\n",
    "\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {}###YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens }\n",
    "\n",
    "for i in range(n_tokens):\n",
    "    token_to_id[tokens[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=0, dtype=np.int32):\n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        print(i)\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[[22 24  7 31  8 31 33 52  0]\n",
      " [22 43 52 10  3 14  0  0  0]\n",
      " [22  0  3 47 46 46 47 33  0]\n",
      " [22 43 47 10 37 31 35 35 33]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units, activation='relu')### YOUR CODE HERE\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens, activation='softmax')### YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = tf.concat([x_t_emb, h_t], 1)### YOUR CODE HERE\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h)### YOUR CODE HERE\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "from keras.objectives import categorical_crossentropy\n",
    "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix))### YOUR CODE HERE\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4VFX6wPHvOyWNQEIJNUCoAtLECAKCioIF166ru3Z2\n0bVscVd/Nmy7ltV13XXdFQuuiq4dFQtYUUAQDNXQpEMCCISEkpB+fn/Mncm0ZCZh0i7v53nyMHPn\nzMy5mfDOue9pYoxBKaWUvTgauwJKKaViT4O7UkrZkAZ3pZSyIQ3uSillQxrclVLKhjS4K6WUDWlw\nV0opG9LgrpRSNqTBXSmlbMjVWG/crl07k5GR0Vhvr5RSzdKSJUv2GmPSIpVrtOCekZFBVlZWY729\nUko1SyKyNZpympZRSikb0uCulFI2pMFdKaVsqNFy7kopFQtlZWXk5ORQXFzc2FWJqYSEBNLT03G7\n3XV6ftTBXUScQBaQa4w5J+ixeOAV4HggD/i5MWZLnWqklFK1kJOTQ8uWLcnIyEBEGrs6MWGMIS8v\nj5ycHHr06FGn16hNWuZ3wJpqHpsE5BtjegNPAn+tU22UUqqWiouLadu2rW0CO4CI0LZt2yO6Gokq\nuItIOjAReKGaIucBL1u33wFOEzv9ppVSTZodw82RnlO0Lfd/ALcDldU83gXYDmCMKQf2A22PqGbV\n2JpXyAMfrqKsorqqKKWUihjcReQcYLcxZsmRvpmITBaRLBHJ2rNnT51eY8PuQ/z32y28+f32I62O\nUkrFRHJycmNXIUQ0LffRwLkisgV4AxgnIq8GlckFugKIiAtIwdOxGsAY85wxJtMYk5mWFnH2bFjj\n+rVneEYb/vHFeorLKur0GkopZXcRg7sx5k5jTLoxJgO4DPjKGHNFULGZwNXW7YutMiamNbWICDee\n2ou9h0qYt35vfbyFUkrViTGG2267jYEDBzJo0CDefPNNAHbu3MnYsWMZOnQoAwcOZN68eVRUVHDN\nNdf4yj755JMxrUudx7mLyINAljFmJjANmC4iG4B9eL4E6s2oXu1oleBiVvZOxg/oUJ9vpZRqRh74\ncBWrdxyI6WsO6NyK+352bFRlZ8yYwfLly1mxYgV79+7lhBNOYOzYsfzvf//jjDPO4O6776aiooKi\noiKWL19Obm4u2dnZABQUFMS03rUK7saYr4Gvrdv3+h0vBi6JZcVqEudycPqADnyx+idKyyuJc+lE\nW6VU45s/fz6XX345TqeTDh06cPLJJ/P9999zwgkncN1111FWVsb555/P0KFD6dmzJ5s2beKWW25h\n4sSJTJgwIaZ1abYzVM8a2IkZS3PJ2rKPUb3bNXZ1lFJNQLQt7IY2duxY5s6dy8cff8w111zDrbfe\nylVXXcWKFSv49NNPmTp1Km+99RYvvvhizN6z2TZ5h3VLBWD1zthegimlVF2NGTOGN998k4qKCvbs\n2cPcuXMZPnw4W7dupUOHDvz617/mV7/6FUuXLmXv3r1UVlZy0UUX8Ze//IWlS5fGtC7NtuXeNjme\n1kluNu451NhVUUopAC644AIWLlzIkCFDEBEee+wxOnbsyMsvv8zjjz+O2+0mOTmZV155hdzcXK69\n9loqKz1zdh555JGY1kXqaVBLRJmZmeZIN+u4ZOoCAN6+YVQsqqSUaobWrFlD//79G7sa9SLcuYnI\nEmNMZqTnNtu0DECvtGQ27NaWu1JKBWvWwb13+2Tyi8rIO1TS2FVRSqkmpVkH955pLQDYklfUyDVR\nSjWmxkov16cjPadmHdzbJccDsK+wtJFropRqLAkJCeTl5dkqwHvXc09ISKjzazTb0TIAbVrEAbCv\nUNMySh2t0tPTycnJoa6LETZV3p2Y6soWwT1PW+5KHbXcbneddyuys2adlkmKc5HgdrDvkAZ3pZTy\n16yDO0CbpDj2FWlwV0opf80/uCfHaYeqUkoFaf7BvUW8BnellArS7IN7aqKb/YfLGrsaSinVpDT7\n4J6iwV0ppUI0++DeKtHFgcNltprAoJRSR6r5B/cEN5UGCkt1s2yllPJq9sE9JdENoKkZpZTy0+yD\ne1K8Z5Lt4dLyRq6JUko1Hc0+uCe6nQAUaVpGKaV8mn1wT4rT4K6UUsGafXBPtIL74TIN7kop5dX8\ng7uVljmsLXellPKJGNxFJEFEFovIChFZJSIPhClzjYjsEZHl1s+v6qe6oTQto5RSoaJZz70EGGeM\nOSQibmC+iMwyxnwXVO5NY8zNsa9izTQto5RSoSIGd+OZ+nnIuuu2fprMdNCkOB0KqZRSwaLKuYuI\nU0SWA7uBz40xi8IUu0hEVorIOyLStZrXmSwiWSKSFastsXQopFJKhYoquBtjKowxQ4F0YLiIDAwq\n8iGQYYwZDHwOvFzN6zxnjMk0xmSmpaUdSb19nA4hzuXQtIxSSvmp1WgZY0wBMAc4M+h4njHGu0v1\nC8DxsaledJLinDpaRiml/EQzWiZNRFKt24nAeGBtUJlOfnfPBdbEspKRJLqdmpZRSik/0YyW6QS8\nLCJOPF8GbxljPhKRB4EsY8xM4Lcici5QDuwDrqmvCoeTGOfUtIxSSvmJZrTMSuC4MMfv9bt9J3Bn\nbKsWPU3LKKVUoGY/QxUgwaXBXSml/NkiuMe5HJRXVjZ2NZRSqsmwRXB3OR2UVjSZeVVKKdXobBHc\n45xCeYW23JVSyssWwd3lcFCmwV0ppXxsEdzdLgdlmpZRSikfewR3p2jLXSml/NgjuGtaRimlAtgj\nuLuEck3LKKWUjy2Cu8vhoFRb7kop5WOL4B7n0rSMUkr5s0Vwdzs1LaOUUv5sEdxdDgfllQbPjoBK\nKaVsEdzjXJ7T0LHuSinlYYvg7nIIgObdlVLKYovg7nZ6W+4a3JVSCuwS3DUto5RSAewR3DUto5RS\nAewR3K20jA6HVEopD1sEd5fT03LXWapKKeVhi+Aepx2qSikVwBbBXdMySikVyBbBXdMySikVKGJw\nF5EEEVksIitEZJWIPBCmTLyIvCkiG0RkkYhk1EdlqxPna7lrcFdKKYiu5V4CjDPGDAGGAmeKyIlB\nZSYB+caY3sCTwF9jW82auZw6zl0ppfxFDO7G45B11239BEfR84CXrdvvAKeJiMSslhG4nTrOXSml\n/EWVcxcRp4gsB3YDnxtjFgUV6QJsBzDGlAP7gbaxrGhNdPkBpZQKFFVwN8ZUGGOGAunAcBEZWJc3\nE5HJIpIlIll79uypy0uE5da0jFJKBajVaBljTAEwBzgz6KFcoCuAiLiAFCAvzPOfM8ZkGmMy09LS\n6lbjMDQto5RSgaIZLZMmIqnW7URgPLA2qNhM4Grr9sXAV6YBd87QtIxSSgVyRVGmE/CyiDjxfBm8\nZYz5SEQeBLKMMTOBacB0EdkA7AMuq7cah6FpGaWUChQxuBtjVgLHhTl+r9/tYuCS2FYtet60THml\nttyVUgpsM0PVcxql5RrclVIKbBLc4zQto5RSAWwR3H1pGe1QVUopwCbB3ak7MSmlVABbBHcRIc7p\noKxS0zJKKQU2Ce7gWfa3TDtUlVIKsFFwdzsdmpZRSimLvYK7pmWUUgqwVXDXtIxSSnnZKLg7KNeW\nu1JKATYK7i6n6B6qSillsU1wd4pQqS13pZQC7BTcHUKFBnellAJsFNxdTg3uSinlZZvg7hTRDlWl\nlLLYJ7g7hMqG2/xJKaWaNNsEd5fDQbku+auUUoCNgrvDgebclVLKYpvg7nI4qNC0jFJKATYK7k6H\ndqgqpZSXrYJ7hW6QrZRSgM2Cu3aoKqWUh22Cu0uHQiqllI9tgrtDc+5KKeUTMbiLSFcRmSMiq0Vk\nlYj8LkyZU0Rkv4gst37urZ/qVs+la8sopZSPK4oy5cAfjTFLRaQlsEREPjfGrA4qN88Yc07sqxgd\nXThMKaWqRGy5G2N2GmOWWrcPAmuALvVdsdpyigZ3pZTyqlXOXUQygOOARWEeHikiK0RklogcW83z\nJ4tIlohk7dmzp9aVrYnLqTl3pZTyijq4i0gy8C7we2PMgaCHlwLdjTFDgH8B74d7DWPMc8aYTGNM\nZlpaWl3rHJbToZt1KKWUV1TBXUTceAL7a8aYGcGPG2MOGGMOWbc/Adwi0i6mNY1Al/xVSqkq0YyW\nEWAasMYY8/dqynS0yiEiw63XzYtlRSNxOhyac1dKKUs0o2VGA1cCP4jIcuvYXUA3AGPMVOBi4Dci\nUg4cBi4zpmFnFHly7rr8gFJKQRTB3RgzH5AIZZ4Gno5VpeoizumgTJcfUEopwEYzVN1OT1pGUzNK\nKWWn4O7yXFyUVWhqRimlbBPc45yeUykp1+CulFL2Ce4uz6loy10ppewU3K2We6m23JVSyj7B3e3U\nlrtSSnnZJrh70zLacldKKRsFd2/LvVRb7kopZZ/gHq8td6WU8rFNcK/KueskJqWUslFw90xi0pa7\nUkrZKLi7rJa7Lh6mlFI2Cu7elnu5pmWUUso+wd3l8LbcNbgrpZR9gru35a5pGaWUslFwd2haRiml\nvGwU3DUto5RSXvYJ7r4OVU3LKKWU7YJ7mbbclVLKRsHdSstUaMtdKaVsFNx9o2W05a6UUrYJ7m6H\nri2jlFJetgnuTmsoZIWOc1dKqcjBXUS6isgcEVktIqtE5HdhyoiIPCUiG0RkpYgMq5/qVs+7/IC2\n3JVSClxRlCkH/miMWSoiLYElIvK5MWa1X5mzgD7WzwjgGevfBiMiOB2iM1SVUoooWu7GmJ3GmKXW\n7YPAGqBLULHzgFeMx3dAqoh0inltI/AEd225K6VUrXLuIpIBHAcsCnqoC7Dd734OoV8A9c7tkJDl\nB87797dc+uzChq6KUko1qmjSMgCISDLwLvB7Y8yBuryZiEwGJgN069atLi9RoziXI2SzjhXbC2L+\nPkop1dRF1XIXETeewP6aMWZGmCK5QFe/++nWsQDGmOeMMZnGmMy0tLS61LdGSXEuikorYv66SinV\n3EQzWkaAacAaY8zfqyk2E7jKGjVzIrDfGLMzhvWMSmKck8Nl5Q39tkop1eREk5YZDVwJ/CAiy61j\ndwHdAIwxU4FPgLOBDUARcG3sqxpZUpwzoOU+feGWxqiGUko1uojB3RgzH5AIZQxwU6wqVVeJbidF\nJVXBfcoHq3y3i0rLSYqLuotBKaWaNdvMUAWr5W6lZTzfN1WmvL8q3FOUUsqWbBbcXew7VApA8HD3\n7flFjVAjpZRqHLYK7r3SWrBjfzGb9xZyqCSwY7WkTEfRKKWOHrYK7kO7pQKw/3AZQx74LOCxknJd\nlkApdfSwVXBPcDkBOBxmrPvaXQcbujpKKdVobBXc492e09l9sLiRa6KUUo3LXsHdarlv36edp0qp\no5utgnuC2xPc84vKwj5eqStGKqWOErYK7vEuz+lMm7857ONluta7UuooYavg7m25Vyd4OWCllLIr\nmwX3mk9Hg7tS6mhhq+CeGKHlHpyWmbE0hz0HS+qzSkop1ShsFdxdTgdDu6ZW+7h/yz3vUAm3vrWC\nSS9/3xBVU0qpBmWr4A7gdla/gGVZRVXLvcJaWGxHweF6r1NxWUXAeyulVH2zXXA/XMMaMhV+QyG9\ntysaYHhkvymzOf/f39b7+yillJftgvvvT+tb7WPlfjl3716rDRHcAVbtqNO2s0opVSe2C+6nD+hQ\n7WNlfjl3b5rEG9uNMWHXpInk/pmrmPSS5u2VUk2L7YJ7Tbwdqj8dKKa0PDAt8+K3W+h/7+xar0vz\n0oItfLl2d2wrqpRSR+ioCu5llZVk5+5nxMNfMv27LUBVx+rMFTsAyMmP3MFaWFLOgo17662eSil1\npI6q4L6zoJhz/jUfgA9X7ASqtuNzOTyjbKLJwf/p7RX84vlF/HRAV59USjVNtgzuo3u3DXt82vxN\nvtvenZq8eXinFdy9Ha3GGKYv3MLSbfnMWbeb3QeLmZ3t+UJYZ60NXxi021M45ToEUinVCFyNXYH6\n8NyVmewoOMz4J+cGHF+6rSBseWOMr+X+549W8+b1I9mw+xBTPqjaVHtI11RWbC9g6hXHs9ua1Vrp\ntwl3bsFhNu05xJg+aQGvXarBXSnVCGzZcm8R76JPh5a++78c0a3G8o/OWuvrbF276yCPfLImZNLR\nrv2eXPwNry7xtfr9i9wwfQlXTlvM/sOByw2X6vZ+SqlGYMvg7pXWMh6Aq0dlANAiLvzaM8/O3cTi\nLft89w8Ul/nSNF7J8aEXOf6zW/cVlgLwyQ87eejj1b614+sa3H/86SDFuqm3UqqOIgZ3EXlRRHaL\nSHY1j58iIvtFZLn1c2/sq1k3D18wCIAOrRL46JaTmPd/46J63rpdB7ly2qKI5R6dtTbk2J0zfuD5\neZvZtLcQgA27D9Wixh4FRaVMeHIud874odbPVUopiC7n/hLwNPBKDWXmGWPOiUmNYmj8gA5seXQi\nACldUqJ+3sY9hSHHeqUlhxwvKqvqUM0NWaPG03J/8osffUcqKw0OR/Vr33gdLPa87uLN+yKUVEqp\n8CK23I0xcwFbRpnOKQlRly0KM3u1qKT6tIkxsDWvkOO7t/Ede+zTdVG9l7efViJ/DyilVFixGi0z\nUkRWADuAPxljVoUrJCKTgckA3brV3MnZEG45rQ+LNuXx/vIdEcsWHC4NORYu4Ht9uGIHT321IeBY\ntCka77rzwXl/pZSKViw6VJcC3Y0xQ4B/Ae9XV9AY85wxJtMYk5mWllZdsXr1xa0nM/Pm0Vx8fDrn\nDO7EvT87NqrnZeeGLvxV0wqUP/4UGsjzCku4f+aqiBOlSso8wd3h13Qvr6jUMfNKqagdcXA3xhww\nxhyybn8CuEWk3RHXrJ70bp/M4PRU/nbJEFomuIlzBf4KuqQm+m4f4zecsrZat4gLuN8rrQXLthXw\n0oItLN/uGW+/+0AxGXd8zJx1nrVpdhQc5sMVOygp93xp+KdlBj/wGeOe+KbO9VFKHV2OOLiLSEcR\nTxgSkeHWa+Yd6es2lDhn1a/A7RTeu3GU7/6L155Q59ctCWrVJ/oNw9xzsJj8wlI+XbULgN+/sRyA\ny577jlteX0ahlcv3ttyXbM2nqLSCbfuK6lyfmny2ahfPfL2xXl5bKdU4IubcReR14BSgnYjkAPcB\nbgBjzFTgYuA3IlIOHAYuM8Y0m52o/XduSnA5aZXo9t1vkxTY+k50O2tMxfiblb0r4H6Cqyq4/3Sg\nhMyHvvClZ/YfLmPJ1nxf8L7CGobptIL7Rc8siPZ06mTy9CUA/OaUXvX6PkqphhMxuBtjLo/w+NN4\nhko2S+KX+6gwhngrTdOnfXJAa3vTw2cjAn3unkV5FIuLBX8JeIc3AuTkF4Xk3cMF8HCjZeav38tJ\nfZps1ksp1UTYcm2Zupo+aQQiwsybR5PeOgmA347rzbDurX3j00f2asu89bVf7nfdTwd9t7fvi27f\n1n2Fpfz29WUBx66YtohND58dMF7eGENFpcHldHDpswvBwFs3jIz4+t/8uAd3NSNyfv7sQuJcDqZP\nGhFVXZVSTYsGd+Da0Rkc3701x3dvDcDg9FTfY7dOOCagrHd44inHpPH1uj11er9vo1wLfvfBEt86\n8/5eW7yNK0/s7rv/6Oy1PPvNJj64aXStJj5d/eLigPvlFZUUllaQkuhmURSvk3HHx1w+vCuPXDg4\n6vdUSjUMW68tE637fnYs5wzuHFXZdsme9Wpcjuh/dQ6BJ38+xHffP0VTnQGdWlU7iWnK+9ms97sS\neOnbLQCc57cJd8YdH/PV2p8A+N+ibVwyNTDtc9vbK0Je9//e/YEhD3xGbbpMXl+8PeqySqmGo8G9\nlu772QDumdifq0d1Dzh+x1n9+PEvZ4V9TpzLwQXHpVf7mr3bJ4ccKymvoKYYu3x7gS9vX12x617K\nAuCu937g+y35FJdVcLi0glvfXM7bS3JCyr+71HOsuKxqPH24xctW5hTUab/ZhpSTX+QbclrfKioN\nz36zscn/TtTRRYN7LbVMcPOrMT0Z0yeNmTeP9h2/4eReIWPmvfyHWwa74sRufP6HsSHHIw17vO2d\nlfS66xN2FByuceVJ/yWI+02ZzcwVucxYllvja/t3BvebMjvgsfzCUs59+lv+FKbl35Sc9Nc5nO93\nJVOf3luWyyOz1vLPL9c3yPspFQ0N7kdgYOfQxch+uH+C73bPdi0AiLOGQU6fNJwrTgxcdsHlcCAi\nDE4PfC2JcmGZUY9+VePjlz/3XcD9vYdCl1EIVlRafdqoyAr8WVsbdrmhotJy/vDmcvYeKmnQ942G\nd0euqd9s9O3SpVRj0+B+BBwOoV1yPH85f6DvWMsEN09c4smvZ1jB3Tu8ckyfNO7/2bHcfuYxXDs6\nw/MaVhA/e1CngNeO92vtjzmCoY+rdwYum5AXRXAPTi94lz346UBx2HXqcwsOM+X9bF6cv5kDxWW+\nMrE0Y2ku7y3L5YnPfqyx3NJt+Szblh/z96+Jfx/FxKfmxfS1//P1hgZLL6maVVQaVjSjz0KD+xHK\nuud0rjgxMP9+7tDO3DKuN3+9yDOK5PYzq0bcuJwObjylN60SPJOlUqxJU9eP7RnwGp1Sq1asvPnU\n3jGr754oWr4f/7Az4H5JeSXLtxcw4uEveX3xNqBq71mAy55byPTvtvLgR6sZfP9nPDJrDZ+t2sVf\nPlpdq87Zmnhf5fXF22pcY+fC/yzggv/U76SvYP5nGM0ciGXb8vlgec2pMfB8aTw2e12DpZdUzf4z\nZwPn/fvbBm881JUG93rgdjr444RjSGsZz5ZHJ3Le0C4hZS4c1oVLM9P51ZgeQGgaZtrVJ9C2RRxt\nWsThckaXojmmQ8uQtE+wnSHrzof6xxeBueMbXl3iCzDfbvSsLOHfcg8et/9WVg73z1zFC/M38+NP\nhyIulFadvEMlrMzxtJT8vyTei9Bn0NBqe3oX/GcBv7OWnKiJ/xdoQ5i+cItvhFVDKi6rYOiDn/HZ\nql2RCzeiH3L3A54Z5s2BBvdG0r1tCx67eAgtwmzfB9C1TRJLpoxn6ZTxIYG/vbV9YLCkeCdXj8zg\nqpHdGT+gQ9gyWVurWh3e1FAk/pO2vK3mmjb+Li6r8HXkrsgpoNddnzA7u+pqoKColC17Azc+Mcaw\na38x/abM4tXvtgKeoZ3nPu35Upnptyxzid8Xy+a9hdz02lLfOj2x9Nb321kQxZyE+lpto6FH30z5\nYJVvhFUkizfv49lvPOsRPfDhKjLu+LjO75tbcJiCorKwO5s1JZXW59xcluLW4N6EeFM0wX87/kv/\nbnjoLBbffXrY5ydbG4M/eN5Anr8qkxl+i6CFk1TNnrI18e4VW5OS8kpfquL2d1YCgWvtTHxqPqf8\n7Wvf/Ze+3UyPOz/hxEe+pLisknvez2Z29k5y8j1XBNm5+wO+lPzXA/rNq0v4+IedXD99SZ33q/33\nnA0sDbrUXrYtn9vfXckvng/dbnFfYSnHPfiZL/8abWw3xjBjaegQ1OpEu45RY7j02YU8YgXj/1rz\nLI5UU1+QynsF2kxiu85QbUpW3DeBpdvySUsObJl7/5gGdmmFy+po/faOcbgcwvZ9RVw8dSHgWdjM\nX3VLFr9/02g27z3EtryqdEpKojtg2GR1du4vjupcgnPP/v8fvFsSLt9ewPvLcnlpwZaQ59/w6lLf\n7T0HAy+DxXq1Oet2s9ZvdMqAewOHbULkrQ0rKw2PWztkrbh3AtvzixjYJSVs3n5fYSnb9xX5Jos9\nP28TfxjfN2BpCfAEcRGhqLScJVvzGdPHs3fBwk153PpW9ENIaxq15K+wpJwpH2Rz99n9aWv97WTc\n8TGXZqbz2MVDIjw7dioqTZNo1e7cf5gW8S5fv5a/f3zxI/06tuTMgZ3CPLNm3ixZNFtlNgXacm9i\nhnVrTdc2SQHHvLNh4/1WluySmkiHVgkc2znFt13g7Wf2C3hedSmfoV1TueC4dOLdVR+/f6dvLAS3\not9fviMkFXPP+z+EDezBDpYEBrmNew/x61eyuPa/3wccD9eZecW0RWTn7qe4rII9Bz05/O37ijhk\nvab/a/9y2nec86/5Ia9RZqWgTnvi64BZwG6ng9Oe+IZ3giaEvfrdVl6Yt4kB937KldMWs8v6Qgwe\nhhopnROp5f7hih08/dV6Xl+8jRlLc0OWbX4rq+arhGnzN9P37llHlFbyX/CurJabyezcf5iDxWU8\nPju67Sf9bdh9iDcWb+O+D7LZuCdwY5yRj3zFhL/PDfu8f3yxPqDhUBve35P/lfR9H2Tzl49W1+n1\n6pu23JuB/p1a8tvT+nDZCV1DHkuMc7LgztOqfW6C20FZhQnbqekf/P2XJK4vE5+ax8MXDvLdD7e7\nVTjBLfdnv9kU9Xsu2JjHHTNWsmt/ScAY+f6dWjHrd2M44He14q1PTn7gBLKc/MP0aNeC/KLAKxtX\nNS24ZdsLmLG0qtPXO8s3eLbvkq35tExwc0zHqiusrC372LSnkEtP6Bp2drC/W6xF5f40oS8A7yzN\n4eZxvX3pvUj+bAWlkvJKEoKu+g6VlPPhih30bp/MCRltwj3ddw5ef/t0HRcOS2dA51YR33tbXhFj\nH58TcGxLXiH9p8zm49+eRM80z6zt5+duYnTvdiGvefrfqzaueXnhVrY8OjHg8V0Har7CfHdJDvlF\npUw6qUfUc0q8w4grKqu+xF5e6OkfuuecAVG9RkPS4N4MiAi3ju9bp+cuvvt0BBh0/2cAXHx81TII\ncX656wPFkVMyR6qwtCKqUSLBPs0+8s7S4MlPa3Ye4LtNedzx7sqQsif9NTDofLNuNz3a9Qgp56pm\n5vHGoL1y56zbzThpH7KBizedtvL+Cb4UgvfYpSd0DdijNye/yLdSaTBvB3NBURlDH/ycR/y+QAF2\nHywmOd5FUlz4/+4jH/mSMwd29N0/UFzGYOvvBTzDfdslh+/E9/fC/M288f12sh84I2LZnILQGdjG\neK5W7pu5CpdDePbKTB76ZA1AQPDeX3Tkf6t/tGZYO0S47qTQz9brpwPFFJdV0L1tC9+ckdLypt47\n4KFpGZtrleCmpRU4hqSn+MbeQ+DiZ7W5Mn/s4oZdBXLxliObDVtSFj5dcOuby9mSF3l3q/s/XM1H\nK0NX53Twvld7AAAR+UlEQVRXM0R1e37g0NAHPlzN+L/PrTbN4k0hLNpUtYHZ/qIy/uY3YSt4BU9/\nJUEpsDtn/OC7XVlpGP7Ql1w/fQnfb9nn6zj2n2iWX1QWsADcvqD00SsLtlBcVsGu/cW+5aWrU12n\n9muLtrLZPy1Xw9/bvPV7mbNuDz8GLJNdRJ71Bb09P7odyeav38u89VUrt4abXPfgR6uZ8OQ3LLSG\n+L63LIcnPqtKE414+EtOfvzrgOd8tymPX7+SxU8Rrg6C7dx/mJMfnxOSRqov2nI/Siy/dzxJca6A\nDi+331o4vzyxGw9GmTvs2CohcqEmZP3u8P+ZdkTZOQxw8/+WhRyrrgM63Iii0opK3/aJwXYdKOZP\nb68IyN3f80F2wGzIjXuqAuOjs9byid9Es2xr/HU43uWl563fGzCkdeoVw6p9znUvBfZl5BeVcd1L\n37NgYx4Pnncs936wqtrnhlsstbyikrvfy6Z1kptl93qW54hmboD/hLsxj80h0e1kUHpK1Mtae3c0\n2/LoRA6XVjDw/k/Dlvvxp0M8881GhnZN5Q9velr0x3dvHdBH4t+f4O0numhY6PwV8CxDMSt7Fx/c\n5Fl7yhjD5r2FvJWVw9a8It5bmsufzohtH1c42nI/SqQmxYUsbJbe2rMZ+B9O70u8y8mkk3pU27H6\nf36dtZ1SAoP7yX3TIr7/yJ5tI5Zplxy4reGxUeRuYyU4lRGND5aHtuZb1DC89MMwa/N7BXfKBnc+\ng+dLo7yikqnfbAxYWG7Bxuq3LL5yWvgW/ytWrjicTUHvXVpe6XuP/y3aVu3zIHBFUc/9Ct9z84vK\nGPvYHCoqDSaKgY/rg0YhHS6riBjYq7uq2H2wuMYrjsKScqbNr+rLuea/3wcsjhfuqmtHQVXj4P6Z\nVV94j85aG/DFPP27rYx74htmWXM9np6zgb99WvtO5NrS4H4UG9atNTNuHMXN4zzLG0w5ZwA3nuK5\nnd46kWtGZXDqMZ7A3Sqx6iKve9sWvtubHj6bl649getGh+Yt/fO0FxznaeWM69c+pPMLPK2rW8b1\nCTh2/tAuTLs6s9r6Z3ZvzTO/rL4FWhvd2oTms72bt8RKcNCsSbjW/8c/7KT33bNiUpe1tVjg7F2/\nsfnRPG/F9gLKKyrZmldIvymzucovpbRtXxEHi8uiSgM+/En0k5q8E77CjdhZveMAz8+ruRO+sKS8\nxtFJxWEmlPlf6b60YEvIshjetNKybZ5Av9UvBdgQwyk1uB/lhnVrHTI2+e0bRvLBTaO5/9xjGWTt\nSuXfWo9zORjUJYVJJ/XA4RBEhB7tqoLjn88fyNQrjmfRXVWjeE7t155rR2fw8AXVt5BPD5pV27t9\nMqf1D51pO/WK4wFITXLTI61FyOPVGdo1tdrHuqQmhhyLczrCHq9Jv06eq40OrSJ3QNYkN8wyEVPe\nzz6i1/QXzWS0d24YyZg+7aJaL8ffef/+lkkvZ4Xkqr0KSytiPmHpkVmejtfg/geAs5+ax6vf1XzF\ncbC4vMYvnOEPfxmxDvuKAn+nE56cy9tZ21mzM3RUWPCclPqgOXcVwn/o282n9qZfx5acekz7gDIf\n3nJSwH3//GTX1omcElQ+rWU89/3sWN/9NyafyMHicr5et9sXELukJrJ0yniG/flzoCrd881tp1Be\naTjtCc/wN//vIncNa+UHm3JOf7qkJnH589+xeW8hr//6RC5/3rMkcve2SQzPaBPQeVteWcm3d4wD\niHp6/T9+PpSOKQkUl1XwzpIcHvgw9mOgF9wxLuJSz7GQmuQOmVDn7/mrMvn1K+GXK/jmx+q3oDxU\nXB4wnDAWXlm4FYeIb05BbeUWHGZHFOsu1eTtrBxuClrk77Z3QkdjASS6679drcFd1SjO5QhZjjic\nX47oxuuLt9E5NZETo8ive8sEr4HjvySC99LVmwa6cFiXoDHX4mtttW0RR14NrVH/4YYPnncss7N3\ncVy3qpa8iPDG5BN5Z2kOnVISuHLa4oCFu6ZPGm6tJ+/3JdYmkYGdUwKWVvBOQHM7HVw7ugcvL9gS\n1Yic2ugc5mrisYsGc3uYYZ2RJMU5SXQ7w/7ujIF21axjBJ4vRH/tW8az+2DkRbWuenFRrRdbi0Y0\nE+Jq8n6YPpRwju/eOmB8v9fjn67zLQQYSXXDUmNJ0zIqaoO6pHDTqb3CPta+VQKL7z6d928aHTIh\npjbiXQ7atIjj8uGhq1v+/dKhQccNnVMTSGsZz+OXBA7PPL1/e84ZXPWl5D8VfUyfNB66YFBIPR0O\n4dLMrr6y5X6tyzF90njz+pGApy9hxX0T+Oz3J/v2w+3fqVXY/P8bk0eGnXw2urfny80h8PjFg1k2\nZXxImZo6lO+Z2D/g/qD0FC4fHvo+kax+8EwmDg7/5d2ldWJIJ7e/4AXsMtq14PEohsn+dKAkZGJa\nsNZJ0U3EiuShCwZGLlQLt47vy4vXnFDt48fcE7oERjgJdVjXqbYiBncReVFEdotI2ISfeDwlIhtE\nZKWIxKaHSzU5H95yEred0S9yQT/nDe3MlUHr3ddERPj+7tOjHr2SFOfi+7tPZ1w/zxXA2L5p/HF8\nXx6/eAh/u6Ru66p4l1guD1pyt7vVKp84qCMpiW4S45y+yV8PXTCQs8Jc4XRMSeDRizzB239bxueu\nzOS5K49n0yMTuSSzK61bhAbRP51xDKsfPIMnLhnCjBtHMbxHG5670tPfMClo4k3LBFfY0SDeHb5+\nc0ov2gS9h/exu86u+qJItmYtv3LdcJLiXKRV03KfesUwUpPiAhan65ySQJfWgVcV79wwMuzza/LY\nRYN9QyaDvXBV9R3s4fRoF9gnMzlo34TamP37Mfz2tD6kJLqZd/updX4daDo595eAp4FXqnn8LKCP\n9TMCeMb6Vyn+edlxtX5O9ItPBZZbfNdptEp0B7TIF945LmCyVjR6pSXTJTWRO88ObB27nA6yHzgj\n4D/myX3TWJmzn67VzB71at0ijtYt4vji1pNZsb2AFvEuJhzbMaDMwxcM4q73qiYgtUrwzCq9yJpV\n/Nb1VYFSRHjr+pFs3nuIOJeD9NZJIcsjAEy/bgSb8woZ2jWVN6yNVoZ1S+XqURm+fQb8f19nHNuR\nm8f19gVF76zYIV1T+b8zjmHOut1cktmVvtaidEPTq1Jbk8f28i2L65UZtHRBywQXT112HNf6jaV/\n+brh5BeW8uGKHXy5djeXhrnSefTCQXRolUC/ToGL4Z3evwOtEjxfQqcP6MAl1gzfqt9h4BXAuUM6\nc3z31lw/fUnIe3iJhJ/U558O69omiT7tk6udQ/HlH09mdvYu36J0wZpEcDfGzBWRjBqKnAe8Yjyr\n6nwnIqki0skYs7OG5yhVZ92sXO+IHoGBo32YyVWdUmoe7TL1iuN94/29EtxOX0dqsOSgxdh+f3pf\nrh6VEdX0fPCMAOrdPjnsY78Y0Y1fjOjGxKfmsWrHgYhfSsN7tGG43++gbVDL/L6fDSAlyc3QJE8A\n9sarZ6/MDGmR/3JEN15btI2S8oqA1q53tFB6aiKjerdjVO/ALR/9h/QN6NwqYCXLAZ1C00o/3H+G\nr67ePL+343zi4E4B6+lcPrybb+evbm2TGNXL894L7xxH1pZ8bnl9GYfLynnBGi7rvwDajBtH8djs\ntfRMa8HJfdN8HbyVxvhSTd3aJNE2OY7rx/b0LSZ27egM7jyrPweKy3hvaS7j+rfn8dnrOKlPu5Av\nivduGs2n2bu4cFgXPlq5k/6dWpIY52LX/sP0Skvm5L5pAcF97m2n+tbTSYpvAsE9Cl2A7X73c6xj\nGtxVvejXsRXzbj81JCjXhf+aKnXhtPbRjaWRPduyaseBkDRKJPecM4CxfdO48TVPoAq3AxiEvzKa\nOKgTry3aFvIF0Tk1kVcnjWBw19DN4L0mj+1JL2tIalKci0cvHERhaQUXD0sPKPffa6ty1Tec3Mu3\nboyX2+kIGP30yIWD+N1pfZg2fxMjelR10ndKSaRjimdkS47fUg8iwkXD0umSmsCwbq15Y7LnSsf/\nC7lP+5a+YaYOgfduHE2BNYTxnon9uW50D9/eyL+2UjhTrVRYsOT4qquqnw3p7Dvu/UIc2CWFxXef\nxvCHPMMou/l1QPdsF/0Q3rpq0NEyIjIZmAzQrVvN28EpVZPgZZHt5I6z+nHZ8K61PsfkeFfAyKbg\n1SH/84thPPPNxrCrRo7s1ZYnfz6EM48N7Tc4KcIG7XcFpa8uC9MZDgQMp/3VmB4hwT2cjikJ3D0x\ndMXFIVY66Fy/oArwxKWh/SzXn9yTL9b8xNzbTyUxzukLvleOzAA8s7fDTayLhfYtE/jbJUN88x6u\nGZXBSwu2kJpUuy/uupBo1nK20jIfGWNCup5F5Fnga2PM69b9dcApkdIymZmZJisrui29lFLRe/Lz\nH3lh3iZWPXhmY1cF8GyFmJt/OORLwjt3oK6BtayislbzHOxCRJYYYyL2LMfiNzMTuMoaNXMisF/z\n7Uo1nj+M79tkAjt4RqxEav3XxdEY2GsjYlpGRF4HTgHaiUgOcB/gBjDGTAU+Ac4GNgBFwLX1VVml\nlH3887Khte5XUNGLZrTM5REeN8BNMauRUuqoUF2Hr4oNva5RSikb0uCulFI2pMFdKaVsSIO7UkrZ\nkAZ3pZSyIQ3uSillQxrclVLKhjS4K6WUDUW1tky9vLHIHmBrHZ/eDtgbw+o0B3rORwc956PDkZxz\nd2NMWqRCjRbcj4SIZEWzcI6d6DkfHfScjw4Ncc6allFKKRvS4K6UUjbUXIP7c41dgUag53x00HM+\nOtT7OTfLnLtSSqmaNdeWu1JKqRo0u+AuImeKyDoR2SAidzR2fWJFRLqKyBwRWS0iq0Tkd9bxNiLy\nuYist/5tbR0XEXnK+j2sFJFhjXsGdSMiThFZJiIfWfd7iMgi67zeFJE463i8dX+D9XhGY9b7SIhI\nqoi8IyJrRWSNiIy08+csIn+w/qazReR1EUmw4+csIi+KyG4RyfY7VuvPVUSutsqvF5Gr61qfZhXc\nRcQJ/Bs4CxgAXC4iobvnNk/lwB+NMQOAE4GbrHO7A/jSGNMH+NK6D57fQR/rZzLwTMNXOSZ+B/jv\nlPxX4EljTG8gH5hkHZ8E5FvHn7TKNVf/BGYbY/oBQ/Ccvy0/ZxHpAvwWyLT2YHYCl2HPz/klIHh/\nw1p9riLSBs9udyOA4cB93i+EWjPGNJsfYCTwqd/9O4E7G7te9XSuHwDjgXVAJ+tYJ2CddftZ4HK/\n8r5yzeUHSLf+4McBHwGCZ2KHK/jzBj4FRlq3XVY5aexzqMM5pwCbg+tu188Z6AJsB9pYn9tHwBl2\n/ZyBDCC7rp8rcDnwrN/xgHK1+WlWLXeq/lC8cqxjtmJdih4HLAI6mKoNx3cBHazbdvhd/AO4Hai0\n7rcFCowx5dZ9/3Pyna/1+H6rfHPTA9gD/NdKR70gIi2w6edsjMkF/gZsA3bi+dyWYP/P2au2n2vM\nPu/mFtxtT0SSgXeB3xtjDvg/Zjxf5bYY3iQi5wC7jTFLGrsuDcwFDAOeMcYcBxRSdakO2O5zbg2c\nh+dLrTPQgtDUxVGhoT/X5hbcc4GufvfTrWO2ICJuPIH9NWPMDOvwTyLSyXq8E7DbOt7cfxejgXNF\nZAvwBp7UzD+BVBHxbtzuf06+87UeTwHyGrLCMZID5BhjFln338ET7O36OZ8ObDbG7DHGlAEz8Hz2\ndv+cvWr7ucbs825uwf17oI/V0x6Hp2NmZiPXKSZERIBpwBpjzN/9HpoJeHvMr8aTi/cev8rqdT8R\n2O93+dfkGWPuNMakG2My8HyOXxljfgnMAS62igWfr/f3cLFVvtm1bo0xu4DtInKMdeg0YDU2/Zzx\npGNOFJEk62/ce762/pz91PZz/RSYICKtraueCdax2mvsDog6dFicDfwIbATubuz6xPC8TsJzybYS\nWG79nI0n3/glsB74AmhjlRc8I4c2Aj/gGY3Q6OdRx3M/BfjIut0TWAxsAN4G4q3jCdb9DdbjPRu7\n3kdwvkOBLOuzfh9obefPGXgAWAtkA9OBeDt+zsDrePoVyvBcoU2qy+cKXGed/wbg2rrWR2eoKqWU\nDTW3tIxSSqkoaHBXSikb0uCulFI2pMFdKaVsSIO7UkrZkAZ3pZSyIQ3uSillQxrclVLKhv4fTcjY\nogzu/MkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75ef6bfe10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DilteitaPPPPPPP\n",
      " KecsinePPPPPPPP\n",
      " GorbarlanPPPPPP\n",
      " RenePPPPPPPPPPP\n",
      " SodilPPPPPPPPPP\n",
      " InboosigdPPPPPP\n",
      " PinlwhaPPPPPPPP\n",
      " MevebloPPPPPPPP\n",
      " GarinaPPPPPPPPP\n",
      " SlyntaPPPPPPPPP\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TrumpyPPPPPPPPP\n",
      " TrumpeltaPPPPPP\n",
      " TrumpantyPPPPPP\n",
      " TrumpalPPPPPPPP\n",
      " TrumpPPPPPPPPPP\n",
      " TrumpeltsePPPPP\n",
      " TrumpyPPPPPPPPP\n",
      " TrumpendaPPPPPP\n",
      " TrumpariPPPPPPP\n",
      " TrumpePPPPPPPPP\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"9NlDTEdpG1Lhg5gu\"\n",
    "COURSERA_EMAIL = \"samorogu@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6d443834fb4eabb27e86cacfd1a783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(10, 50, 55)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(10, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
